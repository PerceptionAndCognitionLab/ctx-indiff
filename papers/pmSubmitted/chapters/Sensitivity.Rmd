---
title: "Individual differences, Sensitivity"
author: "Haaf & Rouder""
output:
  pdf_document: papaja::apa6_pdf
  html_document: default
  word_document: papaja::apa6_word
---

In analysis, it is necessary to specify the prior scales $r_\alpha$, $r_\nu$, and $r_\theta$, which are the standardized scales on individual intercepts, the population mean effect, and individual variation around this mean.  Of these three, the setting of $r_\alpha$ is relatively inconsequential as individual intercepts are specified in all four models.  The other two settings are consequential as they define the dimensionality of the models on $\theta_i$.  If, for example, $r_\theta$ is large, then there is little *a priori* correlation among the individual effects, and the dimensionality of this part of the model is large.  Likewise, if $r_\theta$ is small, then all people have nearly the same effect, and the dimensionality of this part of the model is small.

Before exploring the effects of different settings of $r_\nu$ and $r_\theta$, we provide some guidance as context.  It may seem natural to view dependence of the Bayes factor on these settings as difficult or undesirable.  We think, however, the situation is far more nuanced.  In hierarchical models, the settings are more akin to model specification inasmuch as they set the dimensionality of the model on individual differences.  Setting the scale too small makes the unstructured model resemble too closely the common-effect model; setting the scale too large makes the unstructured model needlessly complex.  To us, dimensionality should be a key consideration in specification.  And where we would expect inference about a model to depend quite heavily on its specification including its complexity, we expect the Bayes factors to depend markedly on these settings.  We first highlight the dependency and then provide some interpretation.

Table `r tab.sens` shows the Bayes factors for different settings of $r_\nu$ and $r_\theta$ for Data Set 1. The first line provides the settings we used for our analysis, $r_\nu = 1/6$ and $r_\theta = 1/10$.  If we assume 300 ms of overall variability, the settings translate into about 50 ms and 30 ms, respectively.  For these settings, the estimates of $\theta_i$ (posterior means) from the unstructured model have a standard deviation of `r round(bf.1$sd * 1000)` ms, which is a data-driven estimate of the true individual variability under the assumption that individuals truly vary.  One way to view this state is that we had expected around 30 ms of individual variation *a priori* but observed only `r round(bf.1$sd * 1000)` ms in the data.  Bayes factors here favor the positive-effects model over the unstructured and common-effect model indicating that while these `r round(bf.1$sd * 1000)` ms are small, they are detectable as individual variation.

The next two lines show the case that the settings are either halved or doubled.  In the second line, we expect a smaller effect overall and smaller individual variation around this effect.  We see here attenuation---the estimated individual variation is 4 ms---and still this small estimate is detectable.  The next line shows the case of doubling the expectations; here we see that although all the conclusions remain, the evidence for the positive-effects model is not as great as before.  It predicts the data 2.7 times better than the common-effect model.  If we continue to increase $r_\theta$, the scale of individual variation, the common-effect model gains, and is preferred.  Indeed, as shown in the fifth and the seventh lines, this trend can be quite extreme.  

To us, these dependencies are reasonable and desirable.  First, in the range that we consider reasonable, the Bayes factors have modest variation.  For example, if we take lines two and three as defining a reasonable range for effect scales, the Bayes factors between the winning model, the positive-effects model, and the common-effect model varies from 2.7-to-1 to 14.2-to-1.  While this variation is moderate, it covers in our opinion the full range of variation across reasonable researchers.  This amount of variation may be small when compared to variation from other subjective elements in research.  Second, if researchers make unreasonable commitments, then the Bayes factors change dramatically.  An $r_\nu$ or $r_\theta$ of 1.0 is unreasonable because nobody expects to find an effect that is equal in size to the variation in response times across repeated trials.  If this were so, no sane researcher would use 50 or 100 repeated trials per person per condition.  In this case, the unreasonable specification leads to predicted effects that are far too variable compared to the data. Consequently, the Bayes factors indicate that these unreasonable specifications are too complex.


